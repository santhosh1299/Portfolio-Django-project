{% extends 'portfolio/base.html' %}

{% block content %}
{% load static %}
<script>
    document.addEventListener('DOMContentLoaded', function () {
        const scrollableNavLinks = document.querySelectorAll('.scrollable-nav .side-heading');
        
        scrollableNavLinks.forEach(function (link) {
            link.addEventListener('click', function (e) {
                e.preventDefault();
                
                const targetId = this.getAttribute('href').substring(1);
                const targetSection = document.getElementById(targetId);
                
                if (targetSection) {
                    window.scrollTo({
                        top: targetSection.offsetTop - 70, // Adjust the offset as needed
                        behavior: 'smooth'
                    });
                }
            });
        });
    });
</script>

<style>
    body {
        margin: 0;
        font-family: 'Lato', sans-serif;
        background-color: #f0f0f0;
        overflow-x: hidden;
    }

nav {
    background-color: #343a40;
    padding: 15px;
    border-radius: 10px;
    box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
}

.navbar-brand {
    color: #fff;
    font-weight: bold;
}

.navbar-toggler-icon {
    background-color: #fff;
}

.navbar-toggler {
    border: none;
}

.navbar-nav .nav-link {
    color: #fff;
    font-weight: bold;
}

.navbar-nav .nav-link:hover {
    color: #ffcc00; /* Change to your desired hover color */
}


   .side-heading {
        color: #343a40;
        text-decoration: none;
        font-weight: normal;
        padding: 13px;
        background-color: #f8f9fa;
        border-radius: 5px;
        cursor: pointer;
        transition: background-color 0.3s ease, color 0.3s ease, transform 0.3s ease;
    }

    .side-heading:hover {
        background-color: #343a40;
        color: #fff;
    }

    .side-heading.active {
        font-weight: bold;
        color: #fff;
        background-color: #555;
    }

   section {
    padding: 30px;
    text-align: left;
    margin: 30px 0;
    background-color: #fff;
    box-shadow: 0 0 15px rgba(0, 0, 0, 0.1);
    border-radius: 15px;
    position: relative; /* Add this line to make room for the fixed header */
    top: 70px; /* Add this line to push the section down below the fixed header */
}

/* Updated Section Heading Styles */
section h2 {
    font-weight: bold;
    color: #343a40;
    font-size: 2em;
    margin-bottom: 20px;
}
section h2 {
    font-size: 2.2em; /* Increase the font size for section headings */
    margin-bottom: 15px; /* Add more spacing between headings and paragraphs */
}

/* Updated Section Paragraph Styles */
section p {
    color: #555;
    line-height: 1.6;
    text-align: justify;
}

/* Updated Image Styles */
section img {
    max-width: 100%;
    height: auto;
    align-self: center;
    border-radius: 10px;
    box-shadow: 0 0 15px rgba(0, 0, 0, 0.1);
}
    .scrollable-nav {
        position: fixed;
        top: 0;
        left: 0;
        width: 200px;
        background-color: transparent;
        display: flex;
        flex-direction: column;
        align-items:stretch;
        padding-top: 60px;
        box-shadow: -2px 0 5px rgba(0, 0, 0, 0.1);
        z-index: 2;
        overflow-y: auto;
    }
article {
        margin-left: 220px; 
        width: calc(100% - 220px); 
    }

.scrollable-nav .side-heading {
    
    text-decoration: none;
    font-weight: normal;
    padding: 13px;
    border-radius: 5px;
    cursor: pointer;
    transition: background-color 0.3s ease, color 0.3s ease;
}

.scrollable-nav .side-heading:hover {
    background-color: #555;
}

h2.title {
        font-size: 3em; /* Adjust the font size as needed */
        font-weight: bold;
        color: #333; /* Set the color as needed */
        text-align: center; /* Center the text */
        margin-bottom: 20px; /* Add margin at the bottom for spacing */
    }
/* Additional styles for the #sectionTitle */
section#sectionTitle {
    background-color: #343a40; /* Set the background color as needed */
    padding: 30px; /* Adjust padding as needed */
    border-radius: 10px; /* Add border-radius for rounded corners */
    border: 2px solid #fff; /* Add a border with a white color */
    box-shadow: 0 0 15px rgba(0, 0, 0, 0.2); /* Add a subtle box shadow */
}

/* Adjust the font size, weight, and color of the title within #sectionTitle */
section#sectionTitle h2.title {
    font-size: 2.5em; /* Adjust the font size as needed */
    font-weight: bold; /* Adjust the font weight as needed */
    color: #fff; /* Set the text color as needed */
    text-align: center; /* Center the text */
    margin-bottom: 20px; /* Add margin at the bottom for spacing */
    text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2); /* Add a subtle text shadow */
}

p {
            font-size: 1.2em;
            line-height: 1.6em;
        }
        img {
    max-width: 100%;
    height: auto;
    border-radius: 10px;
    box-shadow: 0 0 15px rgba(0, 0, 0, 0.2);
    display: block;
    margin: auto; /* Add margin for better separation */
}
p a {
    color: #555;
    display: block;
    text-align: center;
    margin: auto;
    transition: color 0.3s ease, text-decoration 0.3s ease;
}

p a:hover {
    color: #333;
    text-decoration: underline;
}
article p a {
    color: #555;
    display: block;
    text-align: center;
    margin: auto;
    transition: color 0.3s ease, text-decoration 0.3s ease;
}

article p a:hover {
    color: #333;
    text-decoration: underline;
}
h4 {
    font-size: 1.2em; /* You can adjust the value as needed */
    font-weight: bold;
}

/* Increase h3 size and make it bolder */
h3 {
    font-size: 1.4em; /* You can adjust the value as needed */
    font-weight: bold;
}
    
</style>

<nav class="scrollable-nav">
    
    <a class="side-heading" href="#section1">Introduction</a>
    <a class="side-heading" href="#section2">Data Prep_EDA</a>
    <a class="side-heading" href="#section3">Clustering</a>
    <a class="side-heading" href="#section4">ARM</a>
    <a class="side-heading" href="#section5">NaiveBayes</a>
    <a class="side-heading" href="#section6">DecTrees</a>
    <a class="side-heading" href="#section7">SVMs</a>
    <a class="side-heading" href="#section8">Regression</a>
    <a class="side-heading" href="#section9">NN</a>
    <a class="side-heading" href="#section10">Conclusion</a>
</nav>
<article>
<section  id="sectionTitle"  style=" padding-top: 70px;" >
    <h2 class="title" >Lithium Ion Battery Discharge Capacity Prediction <br/>And<br/> Analysis of Charge Cycling</h2>
</section>

<section id="section1" >
    <h2 class ="section-heading" >Introduction</h2>
    <p>
        The Growing urgency of Climate change has led to electrification which has led to an increase in the usage of battery technologies, mainly Lithium-ion battery is predominantly used for many reasons. They possess high energy density which allows them to store more energy in relatively small sizes. Due to this property, it is widely used in portable electronic devices. Long-cycle capacity allows these types of batteries to provide electrical support for longer periods. Mainly, Lithium-ion batteries are environmentally friendly compared to other batteries where these batteries can be recycled using advanced recycling techniques, with a reduced environmental impact. These batteries are virtually low in maintenance, making them suitable for many applications and user-friendly. Their versatility in terms of designs makes it possible to be used in small devices like calculators to battery-powered electric cars, it is available in various designs and sizes including coin cells, pouch cells, and cylindrical cells. Nowadays smartphones require more voltage and in comparison with other rechargeable batteries lithium-ion provides high voltage per cell.   </p>
    <img src={% static 'portfolio/battery-header.jpg' %} alt="Lithium Ion Battery- header" width="750" height="465">
    <p style="font-size: 0.9em; color: #888; margin-top: 5px; transition: color 0.3s ease, text-decoration 0.3s ease;"
   onmouseover="this.style.color='#555'; this.style.textDecoration='underline';"
   onmouseout="this.style.color='#888'; this.style.textDecoration='none';">
   <a href="https://www.miningmagazine.com/technology/news/1458744/direct-lithium-extraction" target="_blank">
       Source: https://www.miningmagazine.com/technology/news/1458744/direct-lithium-extraction
   </a>
</p>

    
    <p>
        The increased dependency on Lithium-ion batteries in every field makes maintenance a crucial aspect, underscoring the potentially disastrous consequences and the heavy reliance on expensive systems for proper care. This holds particularly true for a myriad of applications, spanning from everyday devices like phones and laptops to essential components in vehicles and servers. Indeed, the significance of maintaining lithium-ion batteries cannot be overstated, as these power sources are integral to the seamless operation of our technological landscape.
    </p>
    <img src="https://ul.org/sites/default/files/inline-images/Lithium%20Ion%20Cell%203.png" alt="Lithium Ion Battery" width="750" height="465">
    <p style="font-size: 0.9em; color: #888; margin-top: 5px; transition: color 0.3s ease, text-decoration 0.3s ease;"
   onmouseover="this.style.color='#555'; this.style.textDecoration='underline';"
   onmouseout="this.style.color='#888'; this.style.textDecoration='none';">
   <a href="https://ul.org/research/electrochemical-safety/getting-started-electrochemical-safety/what-are-lithium-ion" target="_blank">
       Source: https://ul.org/research/electrochemical-safety/getting-started-electrochemical-safety/what-are-lithium-ion
   </a>
</p>

    <p>
        According to Consumer Reports' 2023 Annual Auto Reliability Survey, electric vehicles have 79% reliability issues compared to gasoline cars. Battery-related issues are higher when we look into these issues in depth. Some issues like unexpected drops in driving range and reduced battery performance can be mitigated by predictive maintenance, which is the integration of Remaining Useful Life and discharge capacity prediction. It is very useful in guiding consumers to increase the lifespan and reliability of these batteries. Additionally, it can be integrated with dynamic charging algorithms to adapt charging patterns to ensure that minimizes degradation and maximizes the usable life.
    </p>

    <br>
    <p>
        There was some research done on leveraging the Deep Learning Models for battery degradation prediction. This involves analyzing the battery's health and degradation patterns. This research was done purely on MATLAB and there were some limitations on the flexibility compared to other frameworks like TensorFlow or PyTorch. Additionally, MATLAB may not be scalable for large-scale deep-learning objects. Another research was done on the Remaining Useful Life Prediction using the Stacked Autoencoder (SAE) and Gaussian Mixture Regression. This approach led to the introduction of indirect health indicators from the Voltage, Current, and Temperature data to overcome the practical limitations.  </p>
 
    
    <p>
        Research Questions:
        <ol style="font-size: 1.2em; line-height: 1.6em;">
            
            <li>Is there a correlation between battery temperature and measured impedance?</li>
            <li>What is the trend of capacity degradation for Battery #5 #6 #7 over repeated cycles?</li>
            <li>What is the trend of capacity degradation across batteries from different experimental sets over repeated cycles?</li>
            <li>How the discharge capacity is associated with battery impedance?</li>
            <li>How does the discharge capacity measured at the charger vary during charge cycles for Battery group 1?</li>
            <li>Does lower ambient temperature affects the aging of the batteries?</li>
            <li>Find out what causes the difference in the median RUL of battery group #5 and #3?</li>
            <li>Can we predict remaining useful life (RUL) based on observed capacity fade?</li>
            <li>How does ambient temperature vary during different operational profiles?</li>
            <li>Why some battery groups have extreme values while others are in IQR?</li>
        </ol>
    </p>

</section>

<section id="section2" >
    <h2>Data Prep_EDA</h2>
    <h3>Data Collection</h3>
    <p>The data has been gathered from two sources</p>
    <ol style="font-size: 1.2em; line-height: 1.6em;">
        <img src={% static 'portfolio/kaggle-logo.jpeg' %} alt="kaggle-logo" width="250" height="465">
        <br>
        <p style="font-size: 0.9em; color: #888; margin-top: 5px; transition: color 0.3s ease, text-decoration 0.3s ease;"
   onmouseover="this.style.color='#555'; this.style.textDecoration='underline';"
   onmouseout="this.style.color='#888'; this.style.textDecoration='none';">
   <h3>1. Kaggle Data</h3>
   <p>Data Link: </p>
   <a href="https://www.kaggle.com/datasets/patrickfleith/nasa-battery-dataset/data" target="_blank">
    https://Kaggle.com - https://www.kaggle.com/datasets/patrickfleith/nasa-battery-dataset/data
   </a>
   <p>Code Link: </p>
   <a href="https://github.com/santhosh1299/Project/blob/main/data_gathering.ipynb" target="_blank">
    https://github.com/santhosh1299/Project/blob/main/data_gathering.ipynb
   </a>
   <a href="https://github.com/santhosh1299/Project/blob/main/data_cleaning.ipynb" target="_blank">
    https://github.com/santhosh1299/Project/blob/main/data_cleaning.ipynb
   </a>
</p>
        
        <br>
        <p>This data set has been collected from a custom built battery prognostics testbed at the NASA Ames Prognostics Center of Excellence (PCoE). Li-ion batteries were run through 3 different operational profiles (charge, discharge and Electrochemical Impedance Spectroscopy) at different temperatures. Discharges were carried out at different current load levels until the battery voltage fell to preset voltage thresholds. Some of these thresholds were lower than that recommended by the OEM (2.7 V) in order to induce deep discharge aging effects. Repeated charge and discharge cycles result in accelerated aging of the batteries. The experiments were stopped when the batteries reached the end-of-life (EOL) criteria of 30% fade in rated capacity (from 2 Ah to 1.4 Ah).</p>
        <br>
        <p>Raw Data</p>
        <img src={% static 'portfolio/data_clean/kaggle_before.png' %} alt="api-logo" width="815" height="225">
        <br>
        <p>After Cleaning</p>
        <br>
        <img src={% static 'portfolio/data_clean/kaggle_after.png' %} alt="api-logo" width="800" height="290">
        <br>
        <p style="font-size: 0.9em; color: #888; margin-top: 5px; transition: color 0.3s ease, text-decoration 0.3s ease;"
   onmouseover="this.style.color='#555'; this.style.textDecoration='underline';"
   onmouseout="this.style.color='#888'; this.style.textDecoration='none';">

   <h3>2. API Source : </h3>
   <a href="https://open-meteo.com/" target="_blank">
    https://open-meteo.com/ - Historical Weather Data API
   </a>
</p>
        
        <p style="font-size: 0.9em; color: #888; margin-top: 5px; transition: color 0.3s ease, text-decoration 0.3s ease;"
   onmouseover="this.style.color='#555'; this.style.textDecoration='underline';"
   onmouseout="this.style.color='#888'; this.style.textDecoration='none';">
   <p>Endpoint : </p>
   <a href="https://api.open-meteo.com/v1/forecast" target="_blank">
    "https://api.open-meteo.com/v1/forecast"
   </a>
   <p>Code Link : </p>
   <a href="https://github.com/santhosh1299/Project/blob/main/api_data.ipynb" target="_blank">
    "https://github.com/santhosh1299/Project/blob/main/api_data.ipynb"
   </a>
</p>
        <br>
        <p>Raw Data</p>
        <img src={% static 'portfolio/data_clean/api_before.png' %} alt="api-logo" width="941" height="263">
        <br>
        <p>After Cleaning</p>
        <br>
        <img src={% static 'portfolio/data_clean/api_after.png' %} alt="api-logo" width="400" height="222">
        <br>
        
        
        <p>The historical weather data of Moutain View, California where the NASA Ames Prognostics Center of Excellence (PCoE) located for the period of two months to analyse the impact of ambient temperature in the battery aging.</p>

    </ol>

    <h3>Data Cleaning</h3>
    <ol style="font-size: 1.2em; line-height: 1.6em;">
        <br>
        <li> <h4>API Data</h4> </li>
        <br>
        <h4>Checking for Unwanted Columns</h4>
        <p> The raw data has been processed into a data frame and it contains an unwanted redundant index column. As the first step of cleaning it has been removed.</p>
        <br>
        <p>Before Cleaning</p>
        <img src={% static 'portfolio/data_clean/api_removingcols_before.png' %} alt="api-logo" width="450" height="188">
        <br>
        <p>After Cleaning</p>
        <img src={% static 'portfolio/data_clean/api_removingcols_after.png' %} alt="api-logo" width="450" height="188">
        <br>
        <h4>Checking for Incorrect Data Types</h4>
        <p>As the next step, the data is checked for data type. This dataset is in correct datatype, the Date feature as Datetime64 and temperature feature as Float</p>
        <br>
        <img src={% static 'portfolio/data_clean/api_check_datatype.png' %} alt="api-logo" width="450" height="135">
        <br>
        <h4>Checking for Null Values</h4>
        <br>
        <p>The null values are checked for this dataset using isna() function and there were no null values in this dataset.</p>
        <img src={% static 'portfolio/data_clean/api_check_null.png' %} alt="api-logo" width="400" height="161">
        <br>
        <h4>Checking for Duplicated Rows</h4>
        <br>
        <p>There were no duplicated rows in this dataset</p>
        <img src={% static 'portfolio/data_clean/api_duplicate.png' %} alt="api-logo" width="450" height="74">
        <br>
        <h4>Changing the month to match battery dataset</h4>
        <br>
        <p>Due to data unavailability, in this API. The month values are changed from September to April and October to May has been modified to analyse the ambient weather and analyse the changes in other parameters.</p>
        <img src={% static 'portfolio/data_clean/api_manipulation.png' %} alt="api-logo" width="450" height="263">
        <br>
        <br>
        <li> <h4>Kaggle Data</h4> </li>
        <br>
        <h4>Checking for Unwanted Columns</h4>
        <br>
        <p>The raw data contains an unwanted columns. As the first step of cleaning it has been removed.</p>
        <img src={% static 'portfolio/data_clean/kaggle_removingcols.png' %} alt="api-logo" width="450" height="250">
        <br>
        <h4>Checking for Incorrect Data Types</h4>
        <br>
        <p>As the next step, the data is checked for data type. This dataset has 7 features, the Capacity feature as object type was converted to float and other features are in correct data type.</p>
        <br>
        <p>Before Cleaning</p>
        <img src={% static 'portfolio/data_clean/kaggle_check_datatypes_before.png' %} alt="api-logo" width="450" height="209">
        <br>
        <p>After Cleaning</p>
        <img src={% static 'portfolio/data_clean/kaggle_check_datatypes_after.png' %} alt="api-logo" width="450" height="359">
        <br>
        <h4>Checking for Null Values</h4>
        <br>
        <p>The null values are checked for this dataset using isna() function and there were no null values in this dataset.</p>
        <img src={% static 'portfolio/data_clean/kaggle_missing_value.png' %} alt="api-logo" width="450" height="263">
        <br>
        <h4>Merging Metadata with aggregated experiment data</h4>
        <br>
        <p> The Experiment metadata table has been merged with the aggregated values from the experiment data. Mean, median and standard deviation of the Voltage measured, Current measured, Voltage load, Current Load and Time.</p>
        <img src={% static 'portfolio/data_clean/kaggle_discharge_merge_data.png' %} alt="api-logo" width="941" height="263">
        <br>
        <h4>Checking missing values in merged data</h4>
        <br>
        <p>The merged data is checked for missing values and there were no missing values.</p>
        <img src={% static 'portfolio/data_clean/kaggle_merge_missing_value.png' %} alt="api-logo" width="450" height="720">
        <br>
    <h3>Exploratory Data Analysis</h3>
    <ol style="font-size: 1.2em; line-height: 1.6em;">
        <br>

        <h4>Remaining Useful Life(Minutes) of All Battery Groups</h4>
        <br>
        <p>The median of RUL among all the different battery groups. The battery group 5 has the highest and battery group 3 has the lowest.</p>
        <img src={% static 'portfolio/eda/1.png' %} alt="api-logo" width="941" height="263">
         <br>
        <h4>Remaining Useful Life(Minutes) Distribution Analysis</h4>
        <br>
        <p>The battery groups 5 and 6 have values from both extreme values. This indicates that there must be a gap during the experiment.</p>
        <img src={% static 'portfolio/eda/2.png' %} alt="api-logo" width="941" height="263">
        <br>
        <h4>Trend Analysis of Remaining Useful Life(Minutes) During The Experiment</h4>
        <br>
        <p>Analysing the trend of the median Remaining Useful Life(Minutes), it is observed from the visualisation the group 5 and 6 have growing trend</p>
        <img src={% static 'portfolio/eda/3.png' %} alt="api-logo" width="941" height="263">
        <br>
        <h4>Indepth Analysis on Group 5 and 6</h4>
        <br>
        <p>On indepth analysis of battery group 5 and 6 it is confirmed that there was a gap in both experiment groups which is the main reason for the increase in the median remaining useful life.</p>
        <img src={% static 'portfolio/eda/4.png' %} alt="api-logo" width="941" height="263">
        <br> 
        <h4>Clustering Battery Groups on Discharge Capacity and Remaining Useful Life(Minutes)</h4>
        <br>
        <p>On clustering, it can be observed that the RUL and discharge capacity are correlated to eachother.</p>
        <img src={% static 'portfolio/eda/5.png' %} alt="api-logo" width="941" height="263">
        <br>
        <h4>Discharge Capacity Distribution Analysis</h4>
        <br>
        <p>The battery groups 4 and 8 have values from both extreme values. This indicates that it needs an further analysis to find more about the discharge </p>
        <img src={% static 'portfolio/eda/6.png' %} alt="api-logo" width="941" height="263">
        <br>
        <h4>Comparison of Discharge Capacity with that of Remaining Useful Life (Minutes) of Battery #33</h4>
        <br>
        <p>One interesting dip has been observed in the discharge capacity, it must be an outlier or some interesting pattern which needed to explored to find the reason about the dip.</p>
        <img src={% static 'portfolio/eda/7.png' %} alt="api-logo" width="941" height="263">
        <br>
        <h4>Histogram of temperature</h4>
        <br>
        <p>This histogram indicates that some batteries have lower temperatures and some have higher temperatures. </p>
        <img src={% static 'portfolio/eda/8.png' %} alt="api-logo" width="941" height="263">
        <br>
        <h4>Comparison of Temperature with Current Load and Voltage Load </h4>
        <br>
        <p>It can be observed the correlation between the current load and the temperature</p>
        <img src={% static 'portfolio/eda/9.png' %} alt="api-logo" width="941" height="263">
        <br>
        <h4>Temperature vs Remaining Useful Life(Minutes)</h4>
        <br>
        <p>Another interesting observation about the battery group 7 which has higher median RUL within 10deg celsius</p>
        <img src={% static 'portfolio/eda/10.png' %} alt="api-logo" width="941" height="263">
        <br>
        
        



</section>


<section id="section3">
    <h2>Clustering</h2>

    <h3>Overview</h3>
    <p>Clustering is like the pivotal element of unsupervised learning, it helps in bringing together data points based on their natural similarities, in multiple dimensions. It does not need labelled data as required by the supervised learning. Instead, it dives into the data, searching for hidden structures without any guidance or context of the data. As it sifts through the dataset, clusters start to form, like groups of data points, each sharing common patterns or behaviors. 
        These clusters shed light on the different personalities within the data, revealing patterns and connections we might not have noticed before. It is usually used in research where the labels are created by clustering and it helps in providing more context abt the data from the inner lying patterns
        </p>

       

    
    <h4>Types</h4>

    <h4>Partitional Clustering</h4>
    <ul>
        <li>
          It divides the dataset into non-overlapping groups based on their distance from one another. It is suitable for large datasets as it is scalable and efficient.
        </li>
        <li>
          The cluster numbers are specified by the analyst, and there are ways to find an optimal number of clusters best for the data when there is no idea about the actual context of the data.
        </li>
        <li>
          It includes methods like K-means and K-modes.
        </li>
      </ul>
    <h4>KMeans</h4>
    <p>In K-means clustering, the algorithm partitions the data into K clusters by iteratively assigning each data point to the nearest cluster centroid and updating the centroids based on the mean of the points in each cluster. K-means is widely used due to its simplicity and efficiency, but it requires specifying the number of clusters beforehand.</p>

   

    <h4>Hierachical Clustering</h4>
    <p>Hierarchical clustering is a technique that creates a hierarchical tree-like structure of clusters, where each node represents a cluster. This method does not require the analyst to specify the number of clusters beforehand and is particularly useful when the dataset's structure is not well understood.
    </p>
    <h4>Agglomerative  Clustering</h4>
    <ul>
        <li>
          Agglomerative clustering, also known as bottom-up clustering, starts with each data point as a separate cluster. It iteratively merges the closest clusters until a single cluster containing all data points is formed.
        </li>
        <li>
          It considers each cluster as a single cluster and merges two clusters as one until there is only one cluster remaining.
        </li>
      </ul>

    <h4>Linking methods</h4>
    <ul>
        <li>
          Single Linkage: Merge the clusters based on the smallest distance between any points in the two clusters.
        </li>
        <li>
          Complete Linkage: Merge the clusters based on the maximum distance between any points in the two clusters.
        </li>
        <li>
          Average Linkage: Merge the clusters based on the average distance between any points in the two clusters.
        </li>
      </ul>
      

    <h4>Divisive  Clustering</h4>
    <ul>
        <li>
          Divisive clustering, also known as top-down clustering, starts with all data points in a single cluster and recursively splits clusters into smaller clusters until each cluster contains only one data point.
        </li>
        <li>
          It is the opposite of Agglomerative clustering. It clusters the data by considering all data points as one and splits them until each data point becomes a cluster. The splitting on each iteration is based on two criteria: intercluster dissimilarity and intercluster similarity.
        </li>
      </ul>
      
     <h4>Commonly Used Distance Metrics</h4>
     <h3>Euclidean Distance</h3>
<p>
  Perhaps the most widely used distance metric, Euclidean distance measures the straight-line distance between two data points in Euclidean space. It is calculated as the square root of the sum of squared differences between corresponding coordinates of two points. Euclidean distance is suitable for continuous numeric data and assumes that the data points are distributed in a continuous space.
</p>

<h3>Manhattan Distance</h3>
<p>
  Also known as city block distance or taxicab distance, Manhattan distance measures the sum of the absolute differences between corresponding coordinates of two points. It represents the distance traveled along axes at right angles. Manhattan distance is suitable for data with attributes measured on different scales or for which the concept of straight-line distance may not be meaningful.
</p>

<h3>Cosine Similarity</h3>
<p>
  Unlike Euclidean and Manhattan distances, cosine similarity measures the cosine of the angle between two vectors, representing the similarity in direction rather than magnitude. It is commonly used for text data, where documents are represented as vectors of word frequencies or TF-IDF scores. Cosine similarity is robust to differences in vector magnitudes and is effective for measuring similarity between sparse vectors.
</p>


    <h4>Density-based Clustering</h4>
    <ul>
        <li>
          Density-based clustering is a type of clustering algorithm that identifies clusters based on the density of data points in the feature space.
        </li>
        <li>
          Unlike partitioning or hierarchical clustering, which assume that clusters have well-defined boundaries, density-based clustering methods can discover clusters of arbitrary shapes and sizes.
        </li>
        <li>
          One popular density-based clustering algorithm is DBSCAN (Density-Based Spatial Clustering of Applications with Noise).
        </li>
        <li>
          The main advantages of density-based clustering are its ability to handle clusters of arbitrary shapes and sizes and its robustness to noise and outliers.
        </li>
      </ul>
      
      <h3>Data Prep</h3>
      <h4>Code : <a href="https://github.com/santhosh1299/Project/blob/main/API_news.ipynb">News data collection from API</a></h4>
      <p>Clustering algorithms involve mathematical operations such as calculating centroids, updating cluster assignments, or determining cluster distances. These operations are more straightforward to perform on numeric data, as mathematical operations are well-defined for numerical values. Handling categorical or text data requires additional preprocessing steps, such as one-hot encoding or feature scaling, to convert them into numeric format.
      </p>
      <h4>Before</h4>
      <br>
      <p>There are both qualitative and quantitative data types are present in the data</p>
      <img src={% static 'portfolio/clustering/data_prep_before.png' %} alt="api-logo" width="941" height="263">
      <br>
      <h4>After</h4>
      <br>
      <p>It only contains quantitative data and it is ready for clustering</p>
      <img src={% static 'portfolio/clustering/data_prep_after.png' %} alt="api-logo" width="941" height="263">
      <br>
    
      <h3>Code </h3>
      <h4>Kmeans</h4>
      
      <h4>Code : <a href="https://github.com/santhosh1299/Project/blob/main/Clustering-kmeans.ipynb">Kmeans in Python</a></h4>
     
   

      <h4>Hierachical Clustering</h4>
     
      <h4>Code : <a href="https://github.com/santhosh1299/Project/blob/main/Clustering-hclust.ipynb">Hclust in R</a></h4>

     

      <h3>Results</h3>
<p>In the course of our analysis, particular emphasis was placed on the pivotal role of voltage and battery attributes. To illuminate our findings, we employed K-means clustering to discern distinct patterns within our dataset. Leveraging the resulting clusters, we embarked on a process of discretizing our output variables, notably the Remaining Useful Life (RUL) and discharge capacity. With a silhouette score of 11 indicating well-defined clusters, we juxtaposed the clustering outcomes alongside the RUL and discharge capacity values in a scatter plot. This strategic visualization allowed for a comprehensive examination of how these values are clustered and their interrelation within the broader dataset. By integrating clustering results with output variable discretization, we have gained valuable insights into the intricate relationships between input and output variables. This approach not only facilitates the identification of underlying patterns but also enhances our understanding of how these variables contribute to the overall clustering structure, thereby enriching the depth of our analysis and guiding informed decision-making processes.</p>


      <h4>Finding the optimal K value for Kmeans using Silhoutte Method</h4>
      <br>
      <p>The highest silhoutte score was given for K value 11. So it is the optimal value suggested by this method.</p>
      <img src={% static 'portfolio/clustering/silhoutte.png' %} alt="api-logo" width="941" height="263">
      <br>
  

      <h4>Kmeans</h4>


      <h4>Output</h4>
      <br>
      <p>11 clusters are formed for this data by Kmeans model</p>
      <img src={% static 'portfolio/clustering/Clustering output.png' %} alt="api-logo" width="941" height="263">
      <br>
      <h4>Hierachical Clustering</h4>

      <h4>Dendogram using Complete Linkage</h4>
      <br>
      
      <img src={% static 'portfolio/clustering/hclust.png' %} alt="api-logo" width="941" height="263">
      <br>

      <h4>Dendogram using Average Linkage</h4>
      <br>
    
      <img src={% static 'portfolio/clustering/hclust_average.png' %} alt="api-logo" width="941" height="263">
      <br>

      <h4>Dendogram using Single Linkage</h4>
      <br>

      <img src={% static 'portfolio/clustering/hclust_single.png' %} alt="api-logo" width="941" height="263">
      <br>
      
      <h4>Output</h4>
      <br>
      <p>11 clusters are formed for this data by Hclust model</p>
      <img src={% static 'portfolio/clustering/hclust_single.png' %} alt="api-logo" width="941" height="263">
      <br>

     
      <h3>Conclusion</h3>
      <p>Integrating clustering analysis into our modeling framework not only provided valuable insights into battery performance but also significantly enriched our predictive capabilities for both Remaining Useful Life (RUL) and discharge capacity. By stratifying the data into distinct clusters based on similarities in key features, we were able to develop cluster-specific predictive models tailored to the unique degradation patterns observed within each cluster. This approach not only enhanced the accuracy of our RUL predictions but also enabled more precise estimates of discharge capacity over time. For instance, clusters exhibiting accelerated degradation rates were characterized by distinct sets of predictive variables, allowing us to identify early warning signs of capacity loss and predict RUL more accurately than traditional methods.</p>
      <p>Furthermore, the clustering analysis facilitated the identification of critical features driving variations in both RUL and discharge capacity across different battery states. By isolating the most influential variables within each cluster, we were able to refine our predictive models and capture subtle nuances in battery degradation dynamics more effectively. This comprehensive understanding of the underlying factors influencing RUL and discharge capacity enabled us to develop predictive models that are not only more accurate but also more robust to real-world variability. As a result, our approach holds immense promise for optimizing battery management strategies and prolonging the operational lifespan of battery systems in diverse applications, ranging from electric vehicles to renewable energy storage.</p>





</section>

<section id="section4"> 
    <h2>ARM</h2>

    <h4>Overview</h4>
   <p>Association Rule Mining (ARM) is a data mining technique used to discover relationships or associations between items or variables in a dataset. It is commonly applied to transactional data, where each transaction consists of a set of items purchased together. ARM aims to uncover patterns in these transactions that can provide valuable insights for various applications, such as market basket analysis and recommendation systems.

    For example, consider a retail store that records transactions from its customers. Each transaction contains a list of items purchased by a customer during a single visit to the store. By applying ARM to this transactional data, the store can discover associations between different items frequently purchased together. These associations can be represented as rules of the form "If {A} then {B}", indicating that customers who buy item A are likely to buy item B as well.</p> 
    <h4>Describe ARM</h4>
    <p>ARM involves analyzing transactional data to find relationships or associations between items or variables in the data. It helps in various areas such as market basket analysis and recommendation systems.</p>
    
    <h4>Support</h4>
    <p>Support is a measure used in ARM to indicate the frequency of occurrence of a particular itemset in the dataset. It helps identify the most frequent itemsets or combinations of items.</p>
    
    <h4>Confidence</h4>
    <p>Confidence is a measure used in ARM to indicate the reliability of a rule. It measures the likelihood that an item B is purchased given that item A is purchased.</p>
    
    <h4>Lift</h4>
    <p>Lift is a measure used to evaluate the strength of association between two items. It compares the likelihood of two items occurring together to the likelihood of their occurrence being independent of each other.</p>
    
    <h4>What are rules?</h4>
    <p>Association rules are statements that describe the relationships between items in a dataset. They are typically in the form of "If {A} then {B}", where A and B are itemsets.</p>
    
    <h4>What is Apriori?</h4>
    <p>The Apriori algorithm is a popular algorithm used for mining association rules. It works by iteratively generating candidate itemsets and pruning those that do not meet the minimum support threshold.</p>
    
    <h4>Its Working</h4>
    <p>The Apriori algorithm starts by identifying frequent itemsets through iterative candidate generation and pruning. It then generates association rules based on these frequent itemsets, providing valuable insights into the data.</p>

    <h3>Data Prep </h3>
    <h4>Conversion of Data into Transaction Data</h4>
    <p>Transaction data is typically represented as a dataset where each row corresponds to a transaction, and the items purchased in that transaction are listed. To convert raw data into transaction data suitable for Association Rule Mining (ARM), you need to aggregate the data into transactional format. This is commonly done by identifying unique transactions and listing the items associated with each transaction.</p>
    <p>For example, consider a dataset containing sales data for a retail store. Each row in the dataset represents a sale, with columns indicating the transaction ID and the items purchased. To convert this data into transaction format, you would aggregate the items purchased in each transaction and create a list of items associated with each unique transaction ID.</p>
    
    <h4>Why Unnlabelled Transaction Data is used?</h4>
    <p>Unlabeled transaction data is preferred in Association Rule Mining (ARM) due to its flexibility and ability to uncover hidden patterns without predefined labels or categories. With unlabeled data, there's no need to specify predefined categories for items, allowing for the discovery of associations between any items present in the dataset. This approach enables the extraction of insights from raw transactional data, particularly in real-world scenarios where items may not come with predefined labels. Analyzing unlabeled transaction data simplifies the analysis process and facilitates the discovery of generalizable patterns that hold across different contexts. By focusing on the co-occurrence of items in transactions, ARM algorithms can identify common purchasing behaviors and item relationships, providing valuable insights for various industries and domains.</p>
   
    <h4>Code : <a href="https://github.com/santhosh1299/Project/blob/main/API_news.ipynb">News data collection from API</a></h4>
    
    <h4>Before</h4>
    <br>
    <p>Json Response of the news data using API</p>
    <img src={% static 'portfolio/clustering/arm_before.png' %} alt="api-logo" width="941" height="263">
    <br>
    <h4>After</h4>
    <br>
    <p>It contains the itemsets and the transaction ID for each transaction</p>
    <img src={% static 'portfolio/clustering/arm_after.png' %} alt="api-logo" width="941" height="263">
    <br>
  
    <h3>Code </h3>
    
    <h4>Code : <a href="https://github.com/santhosh1299/Project/blob/main/Clustering-kmeans.ipynb">Association Rule Mining in R</a></h4>
   
   <h3>Results</h3>

   <br>
   <p>Association Network visualisation</p>
   <img src={% static 'portfolio/clustering/network.png' %} alt="api-logo" width="941" height="263">
   <br>
   <h4>Top 10 by Support</h4>
   <br>
   <p>The top 10 rules by support</p>
   <img src={% static 'portfolio/clustering/arm_support.png' %} alt="api-logo" width="941" height="263">
   <br>
   <h4>Top 10 by Confidence</h4>
   <br>
   <p>The top 10 rules based on confidence</p>
   <img src={% static 'portfolio/clustering/arm_confidence.png' %} alt="api-logo" width="941" height="263">
   <br>
   <h4>Top 10 by Lift</h4>
   <br>
   <p>The top 10 rules based on lift</p>
   <img src={% static 'portfolio/clustering/arm_lift.png' %} alt="api-logo" width="941" height="263">
   <br>
    <br>
   <p>The association based on "IPhone" keyword on the LHS</p>
   <img src={% static 'portfolio/clustering/iphone_network.png' %} alt="api-logo" width="941" height="263">
   <br>

   <br>
   <p>The association based on "Galaxy" keyword on the LHS</p>
   <img src={% static 'portfolio/clustering/iphone_network.png' %} alt="api-logo" width="941" height="263">
   <br>

   <br>
   <p>The association based on "EV" keyword on the LHS</p>
   <img src={% static 'portfolio/clustering/ev_network.png' %} alt="api-logo" width="941" height="263">
   <br>


<p>One particularly interesting association rule within the dataset is {iphone} => {battery}. With a relatively high support of 1.85%, this rule indicates that the purchase or discussion of iPhones often coincides with mentions of batteries. The confidence value of 61.54% suggests a strong predictive power, implying that when iPhones are present, there's a notable likelihood (approximately 61.54%) that batteries are also mentioned. Additionally, the lift value of 2.21 indicates a positive correlation between iPhones and batteries, meaning that the presence of iPhones tends to increase the likelihood of batteries being mentioned beyond what would be expected by chance alone. This association may reflect the importance of battery life in mobile devices like iPhones, influencing consumer discussions and purchases. Overall, this rule highlights a significant and meaningful association between iPhones and batteries, offering insights into current news related to batteries.</p>
<p>Among the association rules sorted by support, lift, and confidence, a notable pattern emerges regarding the relationship between {iphone} and {battery}. With a high support of 1.85%, the association rule {iphone} => {battery} ranks first, suggesting a prevalent occurrence of discussions or activities related to iPhones alongside mentions of batteries. The high lift value of 8.5756824 further emphasizes a strong positive correlation between iPhones and batteries, indicating that the likelihood of mentioning batteries significantly increases when iPhones are involved compared to their occurrence independently. Additionally, the confidence value of 61.54% underscores the rule's predictive power, indicating that there is a substantial likelihood that batteries will be mentioned when iPhones are present. This association may reflect the importance of battery life in mobile devices like iPhones, influencing consumer discussions and purchase decisions. Overall, these rules provide valuable insights into the interconnectedness of topics within the dataset, highlighting prevalent trends and interests surrounding iPhones and batteries.</p>

<h3>Conclusion</h3>
<p>After delving into our association rules, it's clear as day that certain items love to hang out together in our dataset. Take the iPhone and battery duo, for instance – they're practically joined at the hip! With a whopping support of 1.85%, it's evident that whenever iPhones are on the agenda, batteries are quick to follow suit. And with a confidence rating of 61.54%, it's almost a given that battery chatter will accompany any discussion about iPhones. Not to mention, that lift value of 2.21 tells us this relationship is more than just happenstance – iPhones and batteries really do have a special bond.</p>
<p>But it's not just iPhones and batteries – our association rules reveal a whole web of interconnected items, offering a fascinating glimpse into the trends and interests lurking within our dataset. From smartphones to portable power and market trends, it's like our data has its own secret language, and association rules are the key to unlocking its mysteries.
   <p>Moreover, analyzing news data provides additional insights into the factors that often appear together in headlines. This integration of news data further enriches our understanding of the relationships between different topics and highlights the interconnected nature of current events and consumer interests. By leveraging these insights, businesses can tailor their strategies to align with emerging trends and capitalize on the dynamics driving public discourse. In essence, association rule mining not only reveals hidden patterns within our dataset but also offers a window into the broader landscape of societal trends and preferences.</p> 
</p>
</section>

<section id="section5">
    <h2>NaiveBayes</h2>
    <p>This is the content of Section 4.</p>
</section>

<section id="section6">
    <h2>DecTrees</h2>
    <p>This is the content of Section 4.</p>
</section>

<section id="section7">
    <h2>SVMs</h2>
    <p>This is the content of Section 4.</p>
</section>

<section id="section8">
    <h2>Regression</h2>
    <p>This is the content of Section 4.</p>
</section>

<section id="section9">
    <h2>NN</h2>
    <p>This is the content of Section 4.</p>
</section>

<section id="section10">
    <h2>Conclusion</h2>
    <p>This is the content of Section 4.</p>
</section>
</article>
{% endblock %}
